<!DOCTYPE html>
<html>
<head>
  <title>3.3 LightGBM分類超入門！✨</title>
  <link href="../styles/styles.css" rel="stylesheet"/>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>3.3 LightGBM分類でマジ予測！✨</h1>
      <p>勾配ブースティングと予測の解釈をマスターしちゃおう！💕</p>
    </div>

    <div class="content">
      <!-- アルゴリズム解説 -->
      <div class="card">
        <h2>💫 勾配ブースティング分類のアルゴリズム</h2>
        <div class="feature">
          <p>2.4節の勾配ブースティング回帰と3.2節のロジスティック回帰を組み合わせた超パワフルなアルゴリズムだよ！<br>まずはアルゴリズムの基本をバッチリ理解しちゃお！✨</p>

          <div class="formula">
            <div class="formula-main">
              予測モデルの式はこんな感じ！：
              \[ \hat{y} = \hat{y}^{(0)} + \sum_{k=1}^K w_k(\mathbf{x}) \]  
            </div>
        </div>  

        <div class="formula">
            <div class="formula-main">            
              確率に変換するシグモイド関数：
              \[ \sigma(x) = \frac{1}{1+\exp(-x)} \]
            </div>
          </div>

          <div class="tip">
            <h4>🌟 ポイント</h4>
            <ul>
              <li>初期値から徐々に予測を良くしていくの！</li>
              <li>シグモイド関数で0~1の確率に変換！</li>
              <li>木を500本も作っちゃう！すごくない？✨</li>
            </ul>
          </div>
        </div>
      </div>

      <!-- 実装編 -->
      <div class="card">
        <h2>👩‍💻 LightGBMで学習→予測→評価やってみよう！</h2>
        <div class="feature">
          <div class="code code-python">
# まずはデータを準備！
X = df.drop(['income'], axis=1)
y = df['income']

# 学習用とテスト用にデータを分割！
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, shuffle=True, stratify=y, random_state=0)

# カテゴリ変数をlabel encodingで数値に変換！
for c in cat_cols:
    le = LabelEncoder()
    le.fit(X_train[c])
    X_train[c] = le.transform(X_train[c])
    X_test[c] = le.transform(X_test[c])
          </div>

          <div class="success">
            <h4>💝 前処理のポイント！</h4>
            <ul>
              <li>カテゴリ変数は数値に変換しなきゃ！</li>
              <li>LightGBMはcategory型が使えるけど、今回はSHAPのために数値変換するよ！</li>
            </ul>
          </div>
        </div>
      </div>

      <!-- ハイパーパラメータ -->
      <div class="card">
        <h2>⚡ ハイパーパラメータを設定しよう！</h2>
        <div class="feature">
          <p>LightGBMのパラメータは全部で9個！それぞれの意味をしっかり理解しよう！✨</p>

          <div class="success">
            <h4>💫 主なパラメータたち</h4>
            <table>
              <tr>
                <th>パラメータ</th>
                <th>初期値</th>
                <th>説明</th>
              </tr>
              <tr>
                <td>objective</td>
                <td>'regression'</td>
                <td>損失関数の種類！分類と回帰を切り替えられる！</td>
              </tr>
              <tr>
                <td>num_leaves</td>
                <td>31</td>
                <td>葉の最大数！多いと過学習しちゃうから注意！</td>
              </tr>
              <tr>
                <td>learning_rate</td>
                <td>0.1</td>
                <td>学習率！小さいと時間かかるけど安定するよ！</td>
              </tr>
            </table>
          </div>

          <div class="code code-python">
# パラメータ設定
params = {
    'objective': 'binary',  # 二値分類だよ！
    'num_leaves': 5,       # 葉は5枚に制限！
    'seed': 0,
    'verbose': -1
}
          </div>
        </div>
      </div>

      <!-- SHAPによる解釈 -->
      <div class="card">
        <h2>🔍 SHAPで予測を解釈しちゃお！</h2>
        <div class="feature">
          <p>予測の理由を解明できちゃう超便利なSHAP！各特徴量がどれくらい予測に貢献したか見てみよう！✨</p>

          <div class="code code-python">
# SHAPで解釈
explainer = shap.TreeExplainer(
    model,
    feature_perturbation = 'tree_path_dependent'
)
shap_values = explainer(X_test)

# 可視化
shap.plots.waterfall(shap_values[-3])
          </div>

          <div class="tip">
            <h4>💫 解釈のポイント</h4>
            <ul>
              <li>正の値は予測を上げる方向に働いた特徴量！</li>
              <li>負の値は予測を下げる方向に働いた特徴量！</li>
              <li>棒の長さが影響の大きさを表してるよ！</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</body>
</html>