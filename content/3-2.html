<!DOCTYPE html>
<html>
<head>
  <title>3.2 ロジスティック回帰で二値分類マスター！✨</title>
  <link href="../styles/styles.css" rel="stylesheet"/>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>3.2 ロジスティック回帰でマジ予測！👩‍💻✨</h1>
      <p>線形回帰をベースに確率予測しちゃう超パワフルな手法だよ～！解釈もしやすいからマジおすすめ！💕</p>
    </div>

    <div class="content">
      <!-- アルゴリズム解説 -->
      <div class="card">
        <h2>💫 ロジスティック回帰のアルゴリズム超解説！</h2>
        <div class="feature">
          <p>線形回帰の予測値をラベル1の確率に変換しちゃうの！つまり、予測したい値を0～1の間の確率にするってこと！✨</p>

          <div class="formula">
            <div class="formula-main">
              まずは線形回帰みたいな感じで計算！：
              \[ \hat{y} = w_0 + \sum_{j=1}^m w_jx_j = w_0 + \mathbf{w}^T\mathbf{x} \]
              
              これをシグモイド関数で確率に変換！：
              \[ \sigma(x) = \frac{1}{1+\exp(-x)} \]
            </div>
          </div>

          <div class="success">
            <h4>✨ シグモイド関数のスゴイとこ！</h4>
            <ul>
              <li>マイナスの値を入れると0.5より小さい確率が出てくる！</li>
              <li>プラスの値を入れると0.5より大きい確率になる！</li>
              <li>どんな値入れても0～1の間の値になるの！マジ便利！</li>
            </ul>
          </div>
        </div>
      </div>

      <!-- 学習方法 -->
      <div class="card">
        <h2>🎯 学習の方法をマスターしちゃお！</h2>
        <div class="feature">
          <p>勾配降下法使って学習していくよ！目的関数は二値交差エントロピーってやつを使うの！💪</p>

          <div class="formula">
            <div class="formula-main">
              二値交差エントロピーの式はこんな感じ！：
              \[ l(y_i, p_i) = -[y_i \log(p_i) + (1-y_i)\log(1-p_i)] \]
            </div>
          </div>

          <div class="warning">
            <h4>💡 ここがポイント！</h4>
            <ul>
              <li>正解が1の時は確率が1に近いほど誤差小さい！</li>
              <li>正解が0の時は確率が0に近いほど誤差小さい！</li>
              <li>予測が外れるほど誤差はマジ大きくなる！</li>
            </ul>
          </div>
        </div>
      </div>

      <!-- 実装編 -->
      <div class="card">
        <h2>👩‍💻 実装していっちゃおう！</h2>
        <div class="feature">
          <div class="code code-python">
# まずはデータの前処理！
# カテゴリ変数をone-hotエンコーディング✨
X = pd.concat([X, pd.get_dummies(X['workclass'], 
    prefix='workclass', drop_first=True)], axis=1)

# 特徴量の標準化も忘れずに！
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)

# モデルの学習START！
model = LogisticRegression(max_iter=100, multi_class='ovr',
    solver='liblinear', C=0.1, penalty='l1', random_state=0)
model.fit(X_train, y_train)
          </div>

          <div class="tip">
            <h4>🌈 パラメータの意味</h4>
            <ul>
              <li>C=0.1: 正則化の強さ！小さいほど厳しく！</li>
              <li>penalty='l1': L1正則化で特徴量選択しちゃう！</li>
              <li>solver='liblinear': L1正則化に対応した解法！</li>
            </ul>
          </div>
        </div>
      </div>

      <!-- 評価方法 -->
      <div class="card">
        <h2>📊 予測結果を評価しちゃお！</h2>
        <div class="feature">
          <p>accuracyとF1-scoreで評価するよ！精度は0.84で、F1-scoreは0.64！まずまずの成績！✨</p>

          <div class="code code-python">
# 予測してみよう！
y_pred = model.predict(X_test)
print(f'accuracy = {accuracy_score(y_test, y_pred):.2f}')
print(f'F1-score = {f1_score(y_test, y_pred):.2f}')
          </div>

          <div class="success">
            <h4>💝 解釈のコツ！</h4>
            <ul>
              <li>capital-gainの係数が高いの = お金持ちは収入が高い確率アップ！</li>
              <li>教育レベルも重要な特徴量！</li>
              <li>解釈しやすいのがロジスティック回帰のいいとこ！</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</body>
</html>